# 消费者

## 消费方式

- pull方式

    主动拉取，kafka采用这种方式，如果Kafka没有数据，消费者可能会陷入循环中

- push方式

    不同消费者消费速度的差异会导致推送数据速率难以适应

## 消费者工作流程

### **总体工作流程**

- 一个消费者可以消费一/多个分区的数据
- 每个分区的数据只能由消费者组中一个消费者消费
- 每个消费者的offset由消费者提交到系统主题(__consumer_offsets)保存

### **消费者组原理**

- Consumer Group(CG)由多个消费者组成，所有消费者的group.id相同
  - 每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费
  - 消费者组之间互不影响
  - 如果消费者组中消费者数量超过分区数量，就会有一部分消费者闲置，不接收消息

- Coordinator 辅助实现消费者组的初始化和分区的分配
  - Coordinator节点选择: hash(group.id)%50 (\__consumer_offsets的分区数量) 例如: __consumer_offsets的1号分区在哪个broker上，就选择这个节点的Coordinator作为这个消费者组的老大，组下所有消费者提交offset时就往这个分区提交offset

1. 每个consumer都发送JoinGroup请求
2. 选出一个作为leader
3. 把要消费的topic情况都发给leader消费者
4. leader制定消费方案
5. 把消费方案发给coordinator
6. coordinator把方案下发各consumer
7. 每个消费者都会和coordinator保持心跳(默认3s)，一旦超时(session.timeout.ms=45s)，消费者会被移除，并触发再平衡；或者消费者处理消息的时间过长(max.poll.interval.ms=5min)，也会触发再平衡

### 详细流程

ConsumerNetworkClient

1. SendFetches 向Client发送消费请求
    - fetch.min.bytes 每批次最小抓取大小，默认1字节
    - fetch.max.wait.ms 一批数据未进行抓取的超时时间，默认500ms
    - fetch.max.bytes 每批次最大抓取大小，默认50M
2. send -> onSuccess(callback) 拉取数据放至completedFetches(queue)
3. consumer拉取数据，max.poll.records一次拉取数据返回信息的最大条数，默认500
4. parseRecord 反序列化
5. Interceptor 拦截器
6. 处理数据

## 消费者API

必须配置group.id，但命令行会自动填写随机group.id

```java
//0. 配置
Properties properties = new Properties();
//连接
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"ipaddr:9092");
//反序列化
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
//group.id
properties.put(ConsumerConfig.GROUP_ID_CONFIG,"test");
//1. 创建一个消费者
KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
```

### **独立消费者案例(订阅主题)**

```java
ArrayList<String> topics = new ArrayList<>();
topics.add("demo");
kafkaConsumer.subscribe(topics);
while (true){
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record);
    }
//  如果要退出，在其他线程中控制flag的值
//  if(flag)
//      break;
}
```

### **独立消费者案例(订阅分区)**

```java
ArrayList<TopicPartition> topicPartitions = new ArrayList<>();
topicPartitions.add(new TopicPartition("demo",0));
kafkaConsumer.assign(topicPartitions);
while (true) {
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record);
    }
}
```

### **消费者组案例**

```java
//将订阅主题的代码复制一份然后同时运行，就会分别订阅demo主题的两个分区
//去producer里运行produceCallback()，发送50次数据，并且在每次发送数据后sleep 1ms，使得数据被发往不同分区，观察结果
```

## 生产经验——分区的分配以及再平衡

### **Range以及再平衡**

### **RoundRobin以及再平衡**

### **Sticky以及再平衡**

## offset位移

### **offset的默认维护位置**

### **自动提交offset**

### **手动提交offset**

### **指定offset消费**

### **指定时间消费**

### **漏消费和重复消费分析**

## 生产经验——消费者事务

## 数据积压
