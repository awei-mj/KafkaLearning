# 消费者

## 消费方式

- pull方式

    主动拉取，kafka采用这种方式，如果Kafka没有数据，消费者可能会陷入循环中

- push方式

    不同消费者消费速度的差异会导致推送数据速率难以适应

## 消费者工作流程

### **总体工作流程**

- 一个消费者可以消费一/多个分区的数据
- 每个分区的数据只能由消费者组中一个消费者消费
- 每个消费者的offset由消费者提交到系统主题(__consumer_offsets)保存

### **消费者组原理**

- Consumer Group(CG)由多个消费者组成，所有消费者的group.id相同
  - 每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费
  - 消费者组之间互不影响
  - 如果消费者组中消费者数量超过分区数量，就会有一部分消费者闲置，不接收消息

- Coordinator 辅助实现消费者组的初始化和分区的分配
  - Coordinator节点选择: hash(group.id)%50 (\__consumer_offsets的分区数量) 例如: __consumer_offsets的1号分区在哪个broker上，就选择这个节点的Coordinator作为这个消费者组的老大，组下所有消费者提交offset时就往这个分区提交offset

1. 每个consumer都发送JoinGroup请求
2. 选出一个作为leader
3. 把要消费的topic情况都发给leader消费者
4. leader制定消费方案
5. 把消费方案发给coordinator
6. coordinator把方案下发各consumer
7. 每个消费者都会和coordinator保持心跳(默认3s)，一旦超时(session.timeout.ms=45s)，消费者会被移除，并触发再平衡；或者消费者处理消息的时间过长(max.poll.interval.ms=5min)，也会触发再平衡

### 详细流程

ConsumerNetworkClient

1. SendFetches 向Client发送消费请求
    - fetch.min.bytes 每批次最小抓取大小，默认1字节
    - fetch.max.wait.ms 一批数据未进行抓取的超时时间，默认500ms
    - fetch.max.bytes 每批次最大抓取大小，默认50M
2. send -> onSuccess(callback) 拉取数据放至completedFetches(queue)
3. consumer拉取数据，max.poll.records一次拉取数据返回信息的最大条数，默认500
4. parseRecord 反序列化
5. Interceptor 拦截器
6. 处理数据

## 消费者API

必须配置group.id，但命令行会自动填写随机group.id

```java
//0. 配置
Properties properties = new Properties();
//连接
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"ipaddr:9092");
//反序列化
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
//group.id
properties.put(ConsumerConfig.GROUP_ID_CONFIG,"test");
//1. 创建一个消费者
KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
```

### **独立消费者案例(订阅主题)**

```java
ArrayList<String> topics = new ArrayList<>();
topics.add("demo");
kafkaConsumer.subscribe(topics);
while (true){
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record);
    }
//  如果要退出，在其他线程中控制flag的值
//  if(flag)
//      break;
}
```

### **独立消费者案例(订阅分区)**

```java
ArrayList<TopicPartition> topicPartitions = new ArrayList<>();
topicPartitions.add(new TopicPartition("demo",0));
kafkaConsumer.assign(topicPartitions);
while (true) {
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record);
    }
}
```

### **消费者组案例**

```java
//将订阅主题的代码复制一份然后同时运行，就会分别订阅demo主题的两个分区
//去producer里运行produceCallback()，发送50次数据，并且在每次发送数据后sleep 1ms，使得数据被发往不同分区，观察结果
```

## 生产经验——分区的分配以及再平衡

1. 到底消费者组中的哪个消费者消费哪个分区
2. 四种主流分区分配策略
    - Range
    - RoundRobin
    - Sticky
    - CooperativeSticky

    策略参数partition.assignment.strategy，默认Range + CooperativeSticky。可以同时使用多个分配策略

### **Range以及再平衡**

- Range是对每个topic而言的。
- 首先对同一个topic里的分区按照序号进行排序，并对消费者按照字母顺序进行排序 e.g. [0,1,2,3,4,5,6] [C0,C1,C2]
- 通过分区数/消费者数来决定每个消费者应该消费几个分区，如果除不尽，排在前面的多消费1个分区 [0,1,2],[3,4],[5,6]
- 问题：如果topic非常多，消费者C0都将多消费分区，容易造成数据倾斜
- 如果一个消费者寄了，残余数据交给另一消费者处理 [0,1,2,3,4],[5,6]，新数据重新分配 [0,1,2,3] [4,5,6]

### **RoundRobin以及再平衡**

- RoundRobin针对所有topic而言
- 轮询分区策略，把所有的分区和消费者都列出来，然后按照hashcode排序，最后通过轮询算法来分配分区 [0,3,6],[1,4],[2,5]
- 如果消费[0,3,6]的消费者寄了，旧分区的数据仍然按照轮询分配 [1,4,0,6],[2,5,3]，新数据重新分配 [0,2,4,6],[1,3,5]
- 企业中使用较多

```java
properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, "org.apach.kafka.clients.consumer.RoundRobinAssignor");
```

### **Sticky以及再平衡**

- 粘性分区定义: 在执行一次新的分配前，考虑上一次分配的结果，尽量少的调整分配的变动
- 首先会尽量均衡地分配，组内消费者出现问题后，会尽量保持原有分配的分区不变化 e.g. [0,3,6],[1,4],[2,5] -> [0,6,1,4],[2,3,5] (结果可能不同)

## offset位移

### **offset的默认维护位置**

- 储存位置: 内置topic: __consumer_offsets
- 以key-value形式储存，key=group.id+topic+partition
- 每隔一段时间，kafka会对这个topic进行压缩，即key值对应的value会保留最新数据

- 消费offset案例
- 思想: 既然__consumer_offsets是topic，那就可以被消费。
- 在config/consumer.properties中添加配置exclude.internal.topics=false，默认是true，表示不能消费系统主题。为查看该主题数据，设置为false
- 创建新主题，启动生产者，消费者(用--group指定group.id)(Optional)
- 查看(消费)系统主题

    ```bash
    bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic __consumer_offsets --consumer.config config/consumer.properties --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --from-beginning

    #随便截取两条，当然__consumer_offsets里也会存消费本主题的数据
    [test,demo,1]::OffsetAndMetadata(offset=26, leaderEpoch=Optional[0], metadata=, commitTimestamp=1660835161719, expireTimestamp=None)
    [test,demo,0]::OffsetAndMetadata(offset=94, leaderEpoch=Optional[0], metadata=, commitTimestamp=1660835161765, expireTimestamp=None)
    ```

### **自动提交offset**

相关参数

- enable.auto.commit: 是否开启自动提交offset功能，默认为true
- auto.commit.interval.ms: 自动提交的时间间隔，默认5s

```java
// 改成间隔1s
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 1000);
```

### **手动提交offset**

- commitSync 同步提交 阻塞当前线程，失败自动重试，但也有可能提交失败
- commitAsync 异步提交 有可能提交失败

```java
properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

kafkaConsumer.commitSync();
kafkaConsumer.commitAsync();
```

### **指定offset消费**

auto.offset.reset = earliest | latest | none，默认是latest

- earliest: 自动将偏移量重置为最早的偏移量，相当于--from-beginning
- latest: 自动将偏移量重置为最新的偏移量
- none: 如果未找到先前偏移量，则向消费者抛出异常
- 任意指定位置开始消费

    ```java
    Set<TopicPartition> assignment = kafkaConsumer.assignment();
    //等待分区分配方案完成
    while(assignment.size()==0) {
        kafkaConsumer.poll(Duration.ofSeconds(1));
        assignment = kafkaConsumer.assignment();
    }

    //获得消费者对应分区
    for (TopicPartition topicPartition : assignment) {
        //指定offset
        kafkaConsumer.seek(topicPartition, 50);
    }
    ```

### **指定时间消费**

```java
//把时间转换成offset 获得一天前对应的offset
Map<TopicPartition, Long> topicPartitionLongMap = new HashMap<>();
for (TopicPartition topicPartition : assignment)
    topicPartitionLongMap.put(topicPartition, System.currentTimeMillis() - 1 * 24 * 3600 * 1000);
Map<TopicPartition, OffsetAndTimestamp> offsetMap = kafkaConsumer.offsetsForTimes(topicPartitionLongMap);

//获得消费者对应分区
for (TopicPartition topicPartition : assignment) {
    //指定offset
    kafkaConsumer.seek(topicPartition, offsetMap.get(topicPartition).offset());
}
```

### **漏消费和重复消费分析**

- 重复消费 自动提交offset引起: 每5s提交offset，提交offset后2s，consumer寄了，重启consumer，从上次提交的offset开始消费，导致重复消费
- 漏消费 手动提交offset引起: offset被提交时，数据还在处理时消费者被kill掉，导致这些数据丢失

因此使用消费者事务

## 生产经验——消费者事务

Consumer的下游消费者(如MySQL或Kafka其他主题)也得支持事务，才能做到一次性消费

视频里放到Spark那部分讲了

## 数据积压

数据只存储7天，超出会被删除，处理数据积压的方法:

- 如果Kafka消费能力不足，增加topic的分区数，同时提升消费者组的消费者数量，消费者数=分区数
- 如果下游数据处理不及时，提高每批次拉取数量，如果拉取数据量/处理时间<生产速度，也会造成数据积压
