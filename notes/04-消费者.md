# 消费者

## 消费方式

- pull方式

    主动拉取，kafka采用这种方式，如果Kafka没有数据，消费者可能会陷入循环中

- push方式

    不同消费者消费速度的差异会导致推送数据速率难以适应

## 消费者工作流程

### **总体工作流程**

- 一个消费者可以消费一/多个分区的数据
- 每个分区的数据只能由消费者组中一个消费者消费
- 每个消费者的offset由消费者提交到系统主题(__consumer_offsets)保存

### **消费者组原理**

- Consumer Group(CG)由多个消费者组成，所有消费者的group.id相同
  - 每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费
  - 消费者组之间互不影响
  - 如果消费者组中消费者数量超过分区数量，就会有一部分消费者闲置，不接收消息

- Coordinator 辅助实现消费者组的初始化和分区的分配
  - Coordinator节点选择: hash(group.id)%50 (\__consumer_offsets的分区数量) 例如: __consumer_offsets的1号分区在哪个broker上，就选择这个节点的Coordinator作为这个消费者组的老大，组下所有消费者提交offset时就往这个分区提交offset

1. 每个consumer都发送JoinGroup请求
2. 选出一个作为leader
3. 把要消费的topic情况都发给leader消费者
4. leader制定消费方案
5. 把消费方案发给coordinator
6. coordinator把方案下发各consumer
7. 每个消费者都会和coordinator保持心跳(默认3s)，一旦超时(session.timeout.ms=45s)，消费者会被移除，并触发再平衡；或者消费者处理消息的时间过长(max.poll.interval.ms=5min)，也会触发再平衡

### 详细流程

ConsumerNetworkClient

1. SendFetches 向Client发送消费请求
    - fetch.min.bytes 每批次最小抓取大小，默认1字节
    - fetch.max.wait.ms 一批数据未进行抓取的超时时间，默认500ms
    - fetch.max.bytes 每批次最大抓取大小，默认50M
2. send -> onSuccess(callback) 拉取数据放至completedFetches(queue)
3. consumer拉取数据，max.poll.records一次拉取数据返回信息的最大条数，默认500
4. parseRecord 反序列化
5. Interceptor 拦截器
6. 处理数据

## 消费者API

必须配置group.id，但命令行会自动填写随机group.id

```java
//0. 配置
Properties properties = new Properties();
//连接
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,"ipaddr:9092");
//反序列化
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
//group.id
properties.put(ConsumerConfig.GROUP_ID_CONFIG,"test");
//1. 创建一个消费者
KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);
```

### **独立消费者案例(订阅主题)**

```java
ArrayList<String> topics = new ArrayList<>();
topics.add("demo");
kafkaConsumer.subscribe(topics);
while (true){
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record);
    }
//  如果要退出，在其他线程中控制flag的值
//  if(flag)
//      break;
}
```

### **独立消费者案例(订阅分区)**

```java
ArrayList<TopicPartition> topicPartitions = new ArrayList<>();
topicPartitions.add(new TopicPartition("demo",0));
kafkaConsumer.assign(topicPartitions);
while (true) {
    ConsumerRecords<String, String> records = kafkaConsumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        System.out.println(record);
    }
}
```

### **消费者组案例**

```java
//将订阅主题的代码复制一份然后同时运行，就会分别订阅demo主题的两个分区
//去producer里运行produceCallback()，发送50次数据，并且在每次发送数据后sleep 1ms，使得数据被发往不同分区，观察结果
```

## 生产经验——分区的分配以及再平衡

1. 到底消费者组中的哪个消费者消费哪个分区
2. 四种主流分区分配策略
    - Range
    - RoundRobin
    - Sticky
    - CooperativeSticky

    策略参数partition.assignment.strategy，默认Range + CooperativeSticky。可以同时使用多个分配策略

### **Range以及再平衡**

- Range是对每个topic而言的。
- 首先对同一个topic里的分区按照序号进行排序，并对消费者按照字母顺序进行排序 e.g. [0,1,2,3,4,5,6] [C0,C1,C2]
- 通过分区数/消费者数来决定每个消费者应该消费几个分区，如果除不尽，排在前面的多消费1个分区 [0,1,2],[3,4],[5,6]
- 问题：如果topic非常多，消费者C0都将多消费分区，容易造成数据倾斜
- 如果一个消费者寄了，残余数据交给另一消费者处理 [0,1,2,3,4],[5,6]，新数据重新分配 [0,1,2,3] [4,5,6]

### **RoundRobin以及再平衡**

- RoundRobin针对所有topic而言
- 轮询分区策略，把所有的分区和消费者都列出来，然后按照hashcode排序，最后通过轮询算法来分配分区 [0,3,6],[1,4],[2,5]
- 如果消费[0,3,6]的消费者寄了，旧分区的数据仍然按照轮询分配 [1,4,0,6],[2,5,3]，新数据重新分配 [0,2,4,6],[1,3,5]
- 企业中使用较多

```java
properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, "org.apach.kafka.clients.consumer.RoundRobinAssignor");
```

### **Sticky以及再平衡**

- 粘性分区定义: 在执行一次新的分配前，考虑上一次分配的结果，尽量少的调整分配的变动
- 首先会尽量均衡地分配，组内消费者出现问题后，会尽量保持原有分配的分区不变化 e.g. [0,3,6],[1,4],[2,5] -> [0,6,1,4],[2,3,5] (结果可能不同)

## offset位移

### **offset的默认维护位置**

### **自动提交offset**

### **手动提交offset**

### **指定offset消费**

### **指定时间消费**

### **漏消费和重复消费分析**

## 生产经验——消费者事务

## 数据积压
