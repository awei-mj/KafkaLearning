# Kafka生产者

## 消息发送流程

- main线程
  - Producer -> send(ProducerRecord)
  - Interceptors 拦截器
  - Serializer 序列化器
  - Partitioner 分区器 判断数据发到哪个缓冲队列
- RecordAccumulator(默认32M)
  - DQueue0/DQueue1/DQueue2(ProducerBatch 默认16K)
  - batch.size = 16K, batch存满后sender才会发送数据
  - linger.ms = 0, 如果batch没满,延迟多久发送数据
- sender线程
  - Sender 读取数据
  - NetworkClient
    - broker.id为key, 每个broker最多缓存5个请求
  - Selector 选择请求进行发送
    - 成功 清理请求和缓存队列
    - 失败 重试 最多2073741824次
  - acks 应答机制:
    - 0: 不需要等待应答
    - 1: Leader收到数据后应答
    - -1(all): Leader和ISR队列都收到数据后应答

---

## 异步发送API

数据直接进缓存队列

### **普通异步发送**

```java
//不带回调函数
kafkaProducer.send(new ProducerRecord<>("demo","hello"+i));
```

### **带回调函数的异步发送**

```java
kafkaProducer.send(new ProducerRecord<>("demo", "hello" + i),
                    new Callback() {
                        @Override
                        public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                            if(e==null) {
                                System.out.println("主题: "+recordMetadata.topic());
                                System.out.println("分区: "+recordMetadata.partition());
                            }
                        }
                    });
```

## 同步发送API

```java
kafkaProducer.send(new ProducerRecord<>("demo", "hello" + i)).get();
```

## 生产者分区

拦截器一般不用，序列化器一般都用String的，直接谈分区

### **分区好处**

- **便于合理使用存储资源**，每个partition在一个broker上存储，可以把海量的数据按照分区切割成一块一块存在多台broker上。合理控制分区的任务，可以实现负载均衡的效果。
- **提高并行度**，生产者可以以分区为单位发送数据；消费者可以以分区为单位消费数据。

### **分区策略**

- 默认分区器 DefaultPartitioner
  - 如果在record中指定分区，使用该分区
  - 如果未指定分区，将key的hash值对分区数取模
  - 如果未指定分区，也没设置key，采用sticky partition，当缓冲满了或linger.ms到了之后改变分区。

### **自定义分区器**

- 实现Partitioner接口
- 在properties里进行配置

## 生产经验

### **提高生产者吞吐量**

- batch.size 默认16K
- linger.ms 修改为5-100ms，就有可能达到16K或32K，要注意数据延迟
- compression.type 压缩snappy
- RecordAccumulator 如果分区数量非常多可以修改为64M

### **数据可靠性**

leader维护了一个动态的`in-sync replica set(ISR)`，即保持同步的节点集合，如果follower长时间未向leader发送通信请求或同步数据，则follower会被踢出ISR。时间阈值由replica.lag.time.max.ms参数设定，默认30s

- acks
  - 0: 如果leader失效，数据丢失
  - 1: 如果leader收到数据后还没来得及同步数据就挂了，会选举产生新的leader，新leader没收到数据，但认为发送成功了，故数据丢失。
  - -1: 如果有一个follower故障，迟迟不能与leader同步，怎么办？
  如果分区副本设置为1个，或者ISR里应答的最小副本数量(min.insync.replicas默认为1)设置为1，相当于acks=1，仍然有丢数的风险
  - 完全可靠条件: ACK级别设置为-1 + 分区副本大于等于2 + ISR里应答的副本数量大于等于2

- 总结
  - acks=0，可靠性差，效率高，很少使用
  - acks=1，可靠性中等，效率中等，一般用于传输普通日志，允许丢个别数据
  - acks=-1，可靠性高，效率低，一般用于传输与钱相关的数据

数据重复分析：acks=-1，数据收齐后leader挂了未发送应答数据，产生新leader后会接收重复数据。

### **数据去重**

#### **数据传递语义**

- 至少一次(At Least Once): acks=1, replicas>=2, min.insync.replicas>=2
- 最多一次(At Most Once): acks=0
- 精确一次(Exactly Once): 对重要信息，比如和钱相关，要求既不重复也不丢失

Kafka 0.11版本以后，引入了一项重大特性：幂等性和事务

#### **幂等性**

无论重复发送多少次，都只会持久化一次，保证**单分区单会话内**不重复

Exactly Once = 幂等性 + At Least Once

判断标准：`<PID, Partition, SeqNumber>`

- PID: Producer ID, 每次重启都会分配新的
- Partition: 分区号
- SequenceNumber: 单调自增

参数 enable.idempotence，默认true

#### **生产者事务**

开启事务，必须开启幂等性

Transcation Coordinator 事务协调器

__transaction_state-分区-leader 存储事务信息的特殊主题

默认有50个分区，每个分区负责一部分事务。事务划分是根据hashcode(transactional.id)%50，计算出该事务属于哪个分区。该分区Leader副本所在的broker节点即为这个transactional.id对应的事务协调器节点

producer在使用事务功能前，要想自定义一个唯一的transactional.id，即使客户端挂了，重启后也能继续处理未完成的事务。

```java
//初始化事务
void initTransactions();
//开启事务
void beginTransaction() throws ProducerFencedException;
//在事务内提交已经消费的偏移量(主要用于消费者)
void sendOffsetToTransaction(Map<TopicPartition, OffsetAndMetadata> offsets, String consumerGroupId) throws ProducerFencedException;
//提交事务
void commitTransaction() throws ProducerFencedException;
//放弃事务，回滚事务
void abortTransaction() throws ProducerFencedException;
```

### **数据有序**

- 单分区内，condintional ordered
- 多分区，分区间无序

### **数据乱序**

- Kafka 1.x版本之前保证数据单分区有序，因为max.in.flight.requests.per.connection=1

- Kafka 1.x版本之后要保证单分区有序
  - 未开启幂等性: max.in.flight.requests.per.connection=1
  - 开启幂等性: max.in.flight.requests.per.connection<=5

原因：启用幂等性以后，kafka服务端会缓存producer最近发来的5个request的元数据，对有问题的SeqNumber会暂缓落盘，故无论如何可以保证最近5个request的数据都是有序的
